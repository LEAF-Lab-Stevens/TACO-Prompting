{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38ee2a-4f0a-42d6-a1db-3bbf67a3ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import torch\n",
    "# device = torch.device(\"cuda:1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0944cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "model_name_or_path = \"TheBloke/jackalope-7B-GPTQ\"\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"gptq-4bit-32g-actorder_True\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map='auto',\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=\"main\")\n",
    "\n",
    "from auto_gptq import exllama_set_max_input_length\n",
    "model = exllama_set_max_input_length(model, 8192)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "print(\"*** Pipeline:\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.4,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1dc54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "# get the text report as input\n",
    "import pandas as pd\n",
    "df_text = pd.read_csv('./doc_level_gold_labels.csv')\n",
    "eg = df_text\n",
    "input_text = eg.text.to_list()\n",
    "input_labels = eg.labels.to_list()\n",
    "eg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e8844",
   "metadata": {},
   "source": [
    "## data statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f50514",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg['text_len'] = eg.text.apply(lambda x: len(x))\n",
    "print(\"mean: \", eg.text_len.mean())\n",
    "print(\"min: \", eg.text_len.min())\n",
    "print(\"max: \", eg.text_len.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg['labels_len'] = eg.labels.apply(lambda x: len(x.split(\",\")))\n",
    "print(\"mean: \", eg.labels_len.mean())\n",
    "print(\"min: \", eg.labels_len.min())\n",
    "print(\"max: \", eg.labels_len.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg.labels.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg.final_labels.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aafb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, ast\n",
    "# transform gold labels to be dictionaries\n",
    "label_lst = []\n",
    "\n",
    "label_ids = []\n",
    "\n",
    "for row in eg.iterrows():\n",
    "    id = row[1]['doc_id']\n",
    "    each = row[1][\"final_labels\"]\n",
    "    txt = each.strip('][')\n",
    "    res = re.finditer('{({*[^{}]*}*)}', txt)\n",
    "    # count += 1\n",
    "    res_dict = {}\n",
    "    for idx in res:\n",
    "        # print(id)\n",
    "        idx_res = ast.literal_eval(idx.group())\n",
    "        # print(idx.group())\n",
    "        k = list(idx_res.keys())[0]\n",
    "        \n",
    "        # print(k)\n",
    "        \n",
    "        res_dict[k] = idx_res[k]\n",
    "    # print(res_dict)\n",
    "    # break\n",
    "    label_lst.append(res_dict)\n",
    "    label_ids.append(id)\n",
    "\n",
    "        # else:\n",
    "        #     label_lst.append(np.nan)\n",
    "        #     label_ids.append(id)\n",
    "print(len(label_lst))\n",
    "print(len(label_ids))\n",
    "eg['clean_final_labels'] = label_lst\n",
    "eg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(x) for x in eg.clean_final_labels.to_list()[0].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9280283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "eg['avg_values_per_label'] = eg.clean_final_labels.apply(lambda x: np.mean([[len(each)for each in x.values()]]))\n",
    "print(\"mean: \", eg.avg_values_per_label.mean())\n",
    "print(\"min: \", eg.avg_values_per_label.min())\n",
    "print(\"max: \", eg.avg_values_per_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb156e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg.iloc[309].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg[eg[\"labels_len\"] >= 6].sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c06214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new prompt with two steps\n",
    "example = \"\"\"\n",
    "{\"Symptom1\": [\"redness\", \"redness\"], \"Symptom2\": [\"fever\"], \"Symptom3\": [\"sore\", \"arm\", \"soreness\"], \"Symptom4\": [\"heartfailure\"]}\n",
    "{\"Erythema\": [\"redness\", \"redness\"], \"Pain in extremity\": [\"sore\", \"arm\", \"soreness\"], \"Pruritus\": [\"none\"]}\n",
    "\"\"\"\n",
    "input_template_2nd = \"\"\"\n",
    "Ignore previous conversations.\n",
    "\n",
    "Clinical Notes: {text}\n",
    "\n",
    "First, extract all medical symptoms mentioned in the clinical text above. \n",
    "Second, match the extracted symptoms with the terms in the given suggest list below. If there's no match, provide 'none' for the term.\n",
    "Please follow the order of this suggest list: {suggest} and generate output by following the requirements below:\n",
    "\n",
    "Requirements:\n",
    "1. Adverse event means any symptoms or irregular test results. Therefore, procedure description, negative test results, or only the mention of the test itself are not adverse events.\n",
    "2. If any non symptom, vague mention, or non vaccine related terms appeared in the suggested terms, just provide \"none\" for them in output. \n",
    "3. The output should have the exatracted symptoms as acquired in the first step, and the matched terms with corresponded symptoms as in the second step. Output should be in json format like the example below shows.\n",
    "\n",
    "Example: \n",
    "{example}\n",
    "\n",
    "Here is the JSON output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e7aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new two step prompt structure\n",
    "example = \"\"\"\n",
    "Symptom List: {\"Erythema\": [\"redness\", \"redness\"], \"Pain in extremity\": [\"sore\", \"arm\", \"soreness\"], \"Pruritus\": [\"none\"]}\n",
    "Suggest List: {\"Erythema\": [\"redness\", \"redness\"], \"Pruritus\": [\"none\"]}\n",
    "\"\"\"\n",
    "input_template = \"\"\"\n",
    "Ignore previous conversations.\n",
    "\n",
    "Clinical Notes: {text}\n",
    "\n",
    "First, extract an adverse event list from the clinical text above.\n",
    "Adverse event means any symptoms or irregular test results. Therefore, procedure description, negative test results, or only the mention of the test itself are not adverse events.\n",
    "Then, extract adverse events that indicating each of the suggested terms below from the adverse event list in previous step. \n",
    "Include the terms in the output even if the terms are not explicitly mentioned in the provided report, just provide ‘none’ as the result. \n",
    "\n",
    "Please follow the order of this list: {suggest} and the output should only include a list of symptoms and a list of matched suggest list in json format like the example below shows.\n",
    "\n",
    "Example: \n",
    "{example}\n",
    "\n",
    "Here is the output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up the call\n",
    "# prompt_dic = {'prefix': prompt_prefix, 'cloze': prompt_cloze,'heu': prompt_heu,'cot': prompt_cot}\n",
    "prompt_dic = {'new_prompt': 1}\n",
    "for p in prompt_dic:\n",
    "    answer_lst = []\n",
    "    for row in eg.iterrows():\n",
    "        txt = row[1]['text']\n",
    "        suggest = row[1]['labels']\n",
    "        # input = input_template.format(prompt = prompt_dic[p], suggest = suggest, text = txt)\n",
    "        input = input_template.format(text=txt, suggest = suggest, example = example)\n",
    "\n",
    "        answer = pipe(input)\n",
    "        answer_lst.append(answer[0]['generated_text'][len(input):].strip())\n",
    "    p_col_name = p + 'llm_result'\n",
    "    eg[p_col_name] = answer_lst\n",
    "    result_df = eg[[p_col_name, 'final_labels', 'doc_id', 'text']]\n",
    "    f_name = p + '_result_jackalope_temp_4_2step_prompt.json'\n",
    "    result_df.to_json(f_name)\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49292c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a3ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg = result_df.loc[:,['new_promptllm_result', 'final_labels']]\n",
    "eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddf23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rows in eg.iterrows():\n",
    "    print(rows[0])\n",
    "    print(rows[1][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa94a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
